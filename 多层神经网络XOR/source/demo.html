<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>demo</title>
  <script src="./tf.min.js" module></script>
  <script src="./tfjs-vis.umd.min.js"></script>
  <script src="./data.js"></script>
</head>
<body>
  <h1>多层神经网络XOR</h1>
  <script>
    window.onload = async function () {
      const data = getData(400);
      // 使用 tfjs-vis 的 render.scatterplot 方法绘制散点图
      tfvis.render.scatterplot(
        { name: '训练集' },
        { 
          values: [
            data.filter(p => p.label===1),
            data.filter(p => p.label===0)
          ],
        }
      );

      // 创建一个顺序模型（Sequential Model）
      const model = tf.sequential();
      // 添加一个全连接层（Dense Layer）,这个是隐藏层
      model.add(tf.layers.dense({
        units: 4, // 神经元个数4
        inputShape: [2], // 输入形状为 [2, 3]
        activation: 'relu', // 激活函数
      }));
      // 输出层,这层就不需要写inputShape，它会自动识别上一层的输出
      model.add(tf.layers.dense({
        units: 1, // 输出维度为 1
        activation: 'sigmoid', // 激活函数：sigmoid,输出值是在0~1之间
      }));

      model.compile({
        loss: tf.losses.logLoss, // 对数损失函数,一般用在逻辑回归
        optimizer: tf.train.adam(0.1) // adam 是一种自适应学习率的方法
      });

      // 训练数据
      const inputs = tf.tensor(data.map(p=> [p.x, p.y]));
      const labels = tf.tensor(data.map(p=> p.label));
      // 训练模型
      await model.fit(inputs, labels, {
        batchSize: 40, // 一次处理40数据
        epochs: 10, // 训练 10 个周期
        // tfvis.show.fitCallbacks 来实时显示训练过程（损失值）
        callbacks: tfvis.show.fitCallbacks(
          { name: '训练过程' },
          ['loss']
        )
      });

      // 预测
      const predictData = [3, -2]; // 预测数据
      const output = model.predict(tf.tensor([predictData]));
      alert(`预测结果：${output.dataSync()[0]}`);
    }
  </script>
</body>
</html>